{
    "Subtopic": "Basic Concepts",
    "Questions": [
        {
            "name": "What is deep neural network?",
            "answer": ["Deep neural networks are neural networks with multiple hidden layers between the input and output layers."]
        },
        {
            "name": " What is Epoch?",
            "answer": [
                "The number of times the algorithm runs on the whole training dataset."
            ]
        },
        {
            "name" : "What is cost function/loss function?",
            "answer":[
                "A cost function is used to calculate the cost, which is the difference between the predicted value and the actual value."
            ]
        },
        {
            "name": "What is Weights/ Bias?",
            "answer": [
                "The learnable parameters in a model that controls the signal between two neurons."
            ]                
        },
        {
            "name": "What are the bias terms in neural networks?",
            "answer": ["In simple words, neural network bias can be defined as the constant which is added to the product of features and weights.", 
                        "It is used to offset the result.", 
                        "It helps the models to shift the activation function towards the positive or negative side.",
                        "It is unique for all layers in the network.",
                        "In formula, it is represented as: y = wx + b, where b is the bias term."]
        },
        {
            "name": "Why we need bias terms in neural networks?",
            "answer": ["For example, in linear regression, the bias term is used to shift the regression line from the origin.", 
                        "If we include the bias term 'b' in the activation function, it would allow the neural network to shift the activation function to the left and to the right by simply modifying the values of b.", 
                        "It is used to make the model more flexible to fit the data better."]
        },
        {
            "name": "What is back propagation in neural networks?",
            "answer": ["For supervised learning, backpropagation is a method used to calculate the gradient of the loss function of a neural network with respect to its weights.", 
                        "Using the chain rule to iteratively compute gradients for each layer and find the global minimum of the loss function.", 
                        "It is commonly used by the gradient descent optimization algorithm to update the weight of neurons by calculating the gradient of the loss function.",
                        "In unsupervised learning, backpropagation is used by the autoencoder algorithm."]
        },
        {
            "name": "What is feedforward propagation?",
            "answer": ["Feedforward propagation is the process of moving forward in the neural network.", 
                        "It is the process of moving from the input layer to the output layer.", 
                        "It is also known as forward propagation."]
        },
        {
            "name": "What is gradient vanishing and gradient exploding problem?",
            "answer": [
                "When we back propagate to update the weights, we update the weights by subtract old weights with learning rate and gradient.",
                "In formula, new_weight = old_weight - learning_rate * gradient, where the gradient is the partial derivative of the loss function with respect to the weight.",
                "If the gradient is initialized too small, as number of hidden layers grows, gradient becomes very small and weights will hardly change.",
                "This will hamper the learning process, which is a gradient vanishing problem.",
                "If the gradient is initialized too large, individual derivatives are large, by chain rule, the final gradient(derivative) becomes very large and weights will change dramatically.",
                "This will also hamper the learning process, which is a gradient exploding problem."
            ]
        },
        {
            "name": "Can we initialize all weights to 0?",
            "answer": [
                "No, if we initialize all weights to 0, all neurons will have the same output and same gradient, which means all neurons will be updated in the same way.",
                "This will make the neural network useless."
            ]
        },
        {
            "name": "How to initialize weights?",
            "answer": [
                "We can initialize weights randomly.",
                "For example, we can initialize weights from a normal distribution with mean 0 and standard deviation 1 (Xavier initialization).",
                "We can also initialize weights from a uniform distribution between -1 and 1.",
                "The reason is the mean of the activation function is 0 and the variance stays the same across different layers."
            ]
        },
        {
            "name": "How to prevent gradient vanishing and gradient exploding?",
            "answer": [
                "Using different activation functions for vanishing gradient problem",
                "Using different weight initialization methods",
                "Using gradient clipping with a threshold for gradient exploding problem",
                "Using differnet optimization and learning rate"
            ]           
        },
        {
            "name": "What is learning rate? How it affects the training process?",
            "answer": [
                "Learning rate is a hyperparameter that controls how much we are adjusting the weights of our network with respect the loss gradient.",
                "The lower the value, the slower we travel along the downward slope.",
                "While this might be a good idea (using a low learning rate) in terms of making sure that we do not miss any local minima, it could also mean that we’ll be taking a long time to converge — especially if we get stuck on a plateau region.",
                "If we use a high value for the learning rate, we might overshoot the minima, which means that we may never reach the minima and end up with a very high loss instead."
            ]
        },
        {
            "name": "How we perform hyperparameter tuning with random search or grid search?",
            "answer": ["Hyperparameter tuning is a process to find the best hyperparameters for a model.",
                    "We can use random search or grid search to find the best hyperparameters.",
                    "Random Search is defining a search space as a bounded domain of hyperparameter values and randomly sample points in that domain.",
                    "Grid Search is defining a search space as a grid of hyperparameter values and evaluate every position in the grid."]
        },
        {
            "name": "How to prevent overfitting in neural networks?",
            "answer": [
                "Use more training data",
                "Use regularization",
                "Use dropout",
                "Use data augmentation",
                "Use early stopping",
                "Use batch normalization",
                "Use transfer learning"
            ]
        },
        {
            "name": "What is dropout reugularization?",
            "answer": [
                "Dropout is a regularization technique for neural network.",
                "It is a technique where randomly selected neurons are ignored during training.",
                "This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.",
                "Dropout has the effect of making the training process noisy, forcing nodes within a layer to probabilistically take on more or less responsibility for the inputs."
            ]
        },
        {
            "name": "What is Dropout? How we use it in training and testing?",
            "answer": [
                "AlexNet used dropout method.",
                "Given a keep probability, we can initialize a mask matrix with 0 and 1 by dropout=(np.random.rand(*H1.shape) < p)",
                "Then we can multiply the mask matrix with the hidden layer to get the output.",
                "By p*a+(1-p)*0=pa, where a is the activation of the hidden layer, we can see that the expected value of the output is pa, which is scaled by p.",
                "Since we do not use dropout in testing stage, all the neurons are kept, we need to multiply the testing output with keep probability to align with training output."
            ]
        },
        {
            "name": "What is Inverted Dropout?",
            "answer": [
                "Inverted dropout is a technique that allows us to use dropout without having to change the expected value of our activations.",
                "Inverted dropout scales the activations by 1/p during training time.",
                "This way, the expected value of the activations remains the same as it was without dropout."
            ]
        },
        {
            "name": "What is Batch Normalization?",
            "answer": [
                "Batch normalization is a technique for training very deep neural networks that standardizes the inputs to a layer for each mini-batch.",
                "This has the effect of stabilizing the learning process and dramatically reducing the number of training epochs required to train deep networks.",
                "As the input of the next layer is more stable, the learning process is easier and potentially resolve the gradient vanishing and exploding problem",
                "In formula, if the output of activation function is a, the input of the next layer is b, the mean of a is mu, the variance of a is sigma, the output of batch normalization is bn_output = gamma * (a - mu) / sqrt(sigma^2 + epsilon) + beta, where gamma and beta are learnable parameters, epsilon is a small number to avoid dividing by zero."
            ]
        },
        {
            "name": "Why batch norm works?",
            "answer": [
                "Batch normalization works because it normalizes the input to each unit to have zero mean and unit variance.",
                "This helps to stabilize the learning process and potentially resolve the gradient vanishing and exploding problem.",
                "It also helps to reduce the internal covariate shift(the phenomenon where the distribution of inputs to a deep neural network changes as the network's weights are updated during training), which is the change in the distribution of network activations due to the change in network parameters during training.",
                "Since by the mini-batch normalization, the mean and variance is hust computed by that mini-batch, which add noise to training process, acting as a little regularization."
            ]
        },
        {
            "name": "What is Batch Gradient Descent?",
            "answer": [
                "Batch gradient descent computes the gradient of the cost function w.r.t. to the parameters θ for the entire training dataset.",
                "Since we need to calculate the gradient for the whole training set to perform just one update, batch gradient descent can be very slow and requires large memory.",
                "Batch is great for convex or relatively smooth error manifolds, as we dive straight towards an optimum solution."
            ]
        },
        {
            "name": "What is Stochastic Gradient Descent?",
            "answer": [
                "Stochastic Gradient Descent (SGD) in contrast performs a parameter update for each training example x(i) and label y(i)."
            ]
        },
        {
            "name": "What is mini-batch gradient descent?",
            "answer": [
                "Mini-batch gradient descent takes a small random batch of examples from the training set and computes the gradient of the cost function w.r.t. to the parameters θ for that small random batch only."
            ]
        },
        {
            "name": "Compare Batch Gradient Descent and Stochastic Gradient Descent?",
            "answer": [
                "Convergence Speed: Batch gradient descent takes longer to converge since it computes the gradient using the entire training dataset in each iteration. Stochastic gradient descent, on the other hand, can converge faster since it updates the model parameters after processing each example, which can lead to faster convergence.",
                "Convergence Accuracy: Batch gradient descent is more accurate since it computes the gradient using the entire training dataset. Stochastic gradient descent, on the other hand, can be less accurate since it computes the gradient using a subset of examples, which can introduce more noise and variance in the gradient estimate.",
                "Computation and Memory Requirements: Batch gradient descent requires more computation and memory since it needs to process the entire training dataset in each iteration. Stochastic gradient descent, on the other hand, requires less computation and memory since it only needs to process a single example or a small subset of examples in each iteration.",
                "Optimization of Non-Convex Functions: Stochastic gradient descent is more suitable for optimizing non-convex functions since it can escape local minima and find the global minimum. Batch gradient descent, on the other hand, can get stuck in local minima.",
                "In summary, batch gradient descent is more accurate but slower, while stochastic gradient descent is faster but less accurate."
            ]
        },
        {
            "name": "Problem of Plateau?",
            "answer": [
                "Plateau is a region where the gradient is close to zero for a long time.",
                "In this region, the gradient descent algorithm will take a long time to converge.",
                "Can be solved by great optimization algorithm, such as Adam."
            ]
        },
        {
            "name": "Problem of Saddle Point?",
            "answer": [
                "Saddle point is a point where the gradient is zero but it is not a local minimum.",
                "In this region, the gradient descent algorithm will take a long time to converge."
            ]
        },
        {
            "name": "Difference between saddle point and local minimum?",
            "answer": [
                "Local minimum is a minumum value of all directions, while saddle point is a local minimum in one direction and a local maximum in another direction."]
        }


    ]
}